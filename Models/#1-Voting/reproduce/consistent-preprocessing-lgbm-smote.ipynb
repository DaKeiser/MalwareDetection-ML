{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose  import ColumnTransformer, make_column_selector\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n\nfrom sklearn.impute import SimpleImputer\nimport category_encoders as ce\n\nfrom sklearn import preprocessing\nimport multiprocessing\n\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\n\nfrom sklearn.metrics import make_scorer\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":22,"outputs":[{"output_type":"stream","text":"/kaggle/input/malware-detection-tejas/test.csv\n/kaggle/input/malware-detection-tejas/train.csv\n/kaggle/input/malware-detection-tejas/samplesub.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing Train and test data\ndf = pd.read_csv(\"/kaggle/input/malware-detection-tejas/train.csv\")\ndf.set_index('MachineIdentifier', inplace=True)\ntarget = 'HasDetections'\n# df.drop(target, axis=1, inplace=True)\n\ntest_df = pd.read_csv(\"/kaggle/input/malware-detection-tejas/test.csv\")\ntest_ids = test_df['MachineIdentifier']\ntest_df.set_index('MachineIdentifier', inplace=True)\n\n\n#Dropping columns wiht null values > 60%\ndf.drop(['PuaMode', 'Census_ProcessorClass', 'DefaultBrowsersIdentifier', 'Census_IsFlightingInternal', 'Census_InternalBatteryType', 'Census_ThresholdOptIn', 'Census_IsWIMBootEnabled'], axis = 1, inplace = True)\ntest_df.drop(['PuaMode', 'Census_ProcessorClass', 'DefaultBrowsersIdentifier', 'Census_IsFlightingInternal', 'Census_InternalBatteryType', 'Census_ThresholdOptIn', 'Census_IsWIMBootEnabled'], axis = 1, inplace = True)\n\n#Setting unkonw and unspecified in Census_PrimaryDiskTypeName to a None\ndf['Census_PrimaryDiskTypeName'].replace(to_replace = ['UNKNOWN', 'Unspecified'], inplace = True)\ntest_df['Census_PrimaryDiskTypeName'].replace(to_replace = ['UNKNOWN', 'Unspecified'], inplace = True)\n\n#Making HDD and SSD column as binary\ndf['Census_PrimaryDiskTypeName'].replace(to_replace = ['HDD', 'SSD'], value = [0, 1], inplace = True)\ntest_df['Census_PrimaryDiskTypeName'].replace(to_replace = ['HDD', 'SSD'], value = [0, 1], inplace = True)\n\nprint(\"Data Shape\", df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scikit-Learn imputers require that the missing values are represented with np.nan hence use of the fillna method.\ndf.fillna(np.nan, inplace=True)\ntest_df.fillna(np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the numrical pipeline which takes care of null values in numerical features by putting median\n\nselect_numeric_features = make_column_selector(dtype_include=np.number)\nnumeric_features = select_numeric_features(df)\n# ax1 = df.plot.scatter(x=numeric_features[0],y=numeric_features[1],c='HasDetections',colormap='viridis')\nnumeric_pipeline = make_pipeline(SimpleImputer(strategy='median', add_indicator=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the function of Encoding using OneHotEncoder with MAX_OH_CARDINALITY as threshold\n\nMAX_OH_CARDINALITY = 10\n\ndef select_oh_features(df):\n    \n    hc_features =\\\n        df\\\n        .select_dtypes(['object', 'category'])\\\n        .apply(lambda col: col.nunique())\\\n        .loc[lambda x: x <= MAX_OH_CARDINALITY]\\\n        .index\\\n        .tolist()\n        \n    return hc_features\n\noh_features = select_oh_features(df)\n\nprint(f'N oh_features: {len(oh_features)} \\n')\nprint(', '.join(oh_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the function for Encoding using CatBoostEncoder for the rest of the columns\n\ndef select_hc_features(df):\n    \n    hc_features =\\\n        df\\\n        .select_dtypes(['object', 'category'])\\\n        .apply(lambda col: col.nunique())\\\n        .loc[lambda x: x > MAX_OH_CARDINALITY]\\\n        .index\\\n        .tolist()\n        \n    return hc_features\n\n\nhc_features = select_hc_features(df)\n\nprint(f'N hc_features: {len(hc_features)} \\n')\nprint(', '.join(hc_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pipeline for One Hot Columns to be fillled with Mode and One Hot Encoded after that\n\noh_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pipeline for rest of the columns to be CatBoostEncoded\nhc_pipeline = make_pipeline(ce.CatBoostEncoder())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A column Transformer For Encoding and PreProcessing of the entire dataframe\n\ncolumn_transformer = ColumnTransformer(transformers=\\\n                                       [('numeric_pipeline', numeric_pipeline, select_numeric_features),\\\n                                        ('oh_pipeline', oh_pipeline, select_oh_features),\\\n                                        ('hc_pipeline', hc_pipeline, select_hc_features)],\n                                       n_jobs = multiprocessing.cpu_count(),\n                                       remainder='drop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_columns = list(df.columns)\ntrain_columns.remove(target)\nprint(len(train_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting, Normalization and Column Transformation of data in this step\n\nscaler = MinMaxScaler()\n\nX_train, X_test, y_train, y_test = train_test_split(df[train_columns], df['HasDetections'], test_size=0.05, random_state=42, stratify=df['HasDetections'])\n#index = X_train.index\ntrain_index = X_train.index\nvalidate_index = X_test.index\n\nX_train = column_transformer.fit_transform(X_train,y_train)\nX_test = column_transformer.transform(X_test)\nprint(X_train.shape)\n\nX_train = scaler.fit_transform(X_train,y_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SMOTE or some sampler whichever needs to be called if need be\n\n# sm = SMOTE(random_state=42)\n# X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n\n# nm1 = NearMiss(version=1)\n# X_train, y_train = nm1.fit_resample(X_train, y_train)\n\n# ros = RandomOverSampler(random_state=42)\n# X_train, y_train = ros.fit_resample(X_train, y_train)\n\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=42)\nX_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining gini helper functions for HyperParameter Optimization (took from kaggle)\n\ndef gini(truth, predictions):\n    g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n    gs -= (len(truth) + 1) / 2.\n    return gs / len(truth)\n\ndef gini_xgb(predictions, truth):\n    truth = truth.get_label()\n    return 'gini', -1.0 * gini(truth, predictions) / gini(truth, truth)\n\ndef gini_lgb(truth, predictions):\n    score = gini(truth, predictions) / gini(truth, truth)\n    return 'gini', score, True\n\ndef gini_sklearn(truth, predictions):\n    return gini(truth, predictions) / gini(truth, truth)\n\ngini_scorer = make_scorer(gini_sklearn, greater_is_better=True, needs_proba=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#HyperParameter OOptimizaiton using HyperOpt\n\ndef objective(params):\n    params = {\n        'num_leaves': int(params['num_leaves']),\n        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n    }\n    \n    clf = lgbm.LGBMClassifier(\n        n_estimators=500,\n        learning_rate=0.01,\n        **params\n    )\n    \n    score = cross_val_score(clf, X_train, y_train, scoring=gini_scorer, cv=StratifiedKFold()).mean()\n    print(\"Gini {:.3f} params {}\".format(score, params))\n    return score\n\nspace = {\n    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n}\n\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=10)\n\nprint(\"Hyperopt estimated optimum {}\".format(best))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the params that we find in previous step here in the lgbmClassifier and fit the X_train to it.\n\n'''model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=14,min_weight_fraction_leaf=0.0004),\n                                sampling_strategy='not majority',\n                                replacement=False,\n                                random_state=0, n_jobs = -1, verbose=1,\n                                oob_score=1,warm_start=0)'''\n'''base = SGDClassifier(max_iter=2000, loss = 'log', verbose=1, n_jobs=4, class_weight=\"balanced\", verbose=1)\nmodel = EasyEnsembleClassifier(base_estimator=base,\\\n                               n_jobs = 4, random_state=42, sampling_strategy='all',verbose=1, n_estimators=100)'''\n# model = CatBoostClassifier(verbose=1, n_estimators=400, depth=5, min_data_in_leaf = 2,\\\n#                           random_seed=67, learning_rate=0.5, auto_class_weights = 'Balanced', custom_metric=['Logloss',\n#                                           'AUC:hints=skip_train~false'])\n\nmodel = lgbm.LGBMClassifier(objective='binary',n_estimators=200,learning_rate=0.01,colsample_bytree = 0.5226745882649404, num_leaves = 24) \n\n# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n# scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n# model = ExtraTreesClassifier(n_estimators=100, random_state=0,class_weight='balanced')\n# model = RandomForestClassifier(n_estimators=200, random_state=69, class_weight='balanced')\n# model = AdaBoostClassifier(n_estimators=200, learning_rate = 0.1, random_state=42)\n# model = HistGradientBoostingClassifier(max_iter=500)\n# model = XGBClassifier(sampling_method='gradient_based',eta = 0.2, max_depth = 10,verbosity=2, gamma=10, tree_method = 'gpu_hist')\n# model = XGBClassifier(base_score=0.7, learning_rate=0.3, sampling_method='gradient_based',\\\n#                       eta = 0.5, max_depth = 20,verbosity=2, gamma=20, tree_method = 'gpu_hist')\n\nmodel.fit(X_train, y_train)\n\ny_train_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Was done to test stacking but If used smote then entries increase and difficult to identify index for writing to CSV.\n\n# Y = model.predict_proba(X_train)\n# preds_train = Y.transpose()[1]\n# train_res = pd.DataFrame()\n# train_res['MachineIdentifier'] = train_index\n# train_res['HasDetections'] = preds_train\n# train_res.to_csv('train_model_probas.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(y_train, return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import roc_auc_score, plot_roc_curve\n\nprobabilities = model.predict_proba(X_test)\npreds_train = probabilities.transpose()[1]\nvalidate_res = pd.DataFrame()\nvalidate_res['MachineIdentifier'] = validate_index\nvalidate_res['HasDetections'] = preds_train\nvalidate_res.to_csv('validate_model_probas.csv',index=False)\nvalidate_res.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(np.around(probabilities, decimals=6), columns = [\"0\", \"1\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(model, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test, pred['1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = column_transformer.transform(test_df) \nX = scaler.transform(X)\nY = model.predict_proba(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = Y.transpose()[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame()\nres['MachineIdentifier'] = test_ids\nres['HasDetections'] = preds\nres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.to_csv('test_model_probas.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(res[res['HasDetections'] > 0.5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}